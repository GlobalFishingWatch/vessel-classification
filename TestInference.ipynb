{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import tensorflow as tf\n",
    "from classification.models import model\n",
    "from classification import metadata\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import pytz\n",
    "from classification import run_inference\n",
    "import json\n",
    "import pandas\n",
    "import matplotlib.pyplot as plt\n",
    "import subprocess\n",
    "import pandas as pd\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TYPE_ORDER = {x : i for (i, x) in \n",
    "    enumerate(['PORT_ENTRY',\n",
    "               # The order of PORT_GAP is somewhat arbitrary, but it\n",
    "               # Shouldn't matter as long as it occurs between ENTRY\n",
    "               # and EXIT.\n",
    "               'PORT_GAP',\n",
    "               'PORT_STOP_BEGIN',\n",
    "               'PORT_STOP_END',\n",
    "               'PORT_EXIT'])}\n",
    "\n",
    "TYPE_ORDER['PORT_GAP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fishing_df = pandas.read_csv('classification/data/det_info_v20190520.csv')\n",
    "ranges_df = pandas.read_csv('classification/data/det_ranges_v20190520.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_transit_only = set()\n",
    "for x in ranges_df.itertuples():\n",
    "    if x.is_fishing > 0.5:\n",
    "        not_transit_only.add(x.id)\n",
    "        \n",
    "transit_only_mask = np.array([x not in not_transit_only for x in fishing_df.id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "has_duplicates = set()\n",
    "for x in set(fishing_df.id):\n",
    "    mask = (fishing_df.id == x)\n",
    "    if mask.sum() > 1:\n",
    "        has_duplicates.add(x)\n",
    "has_duplicates = sorted(has_duplicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in has_duplicates[::10]:\n",
    "    mask = (fishing_df.id == x)\n",
    "    print(fishing_df[mask])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'id', u'confidence', u'transit_only', u'length', u'tonnage',\n",
       "       u'engine_power', u'label', u'crew_size', u'split'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fishing_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "other_seines 0 0\n",
      "other_seines 0 0\n",
      "tuna_purse_seines 19 7\n",
      "tuna_purse_seines 7 6\n",
      "other_purse_seines 2 1\n",
      "other_purse_seines 1 1\n"
     ]
    }
   ],
   "source": [
    "from classification.metrics import compute_fishing_metrics as cfm\n",
    "coarse_mapping = {k : v for (k, v) in cfm.coarse_mapping}\n",
    "train_mask = (fishing_df.split == 'Training')\n",
    "for atm in coarse_mapping['seiners']:\n",
    "    mask = (fishing_df.label == atm)\n",
    "    print(atm, (mask & train_mask).sum(), (mask & ~train_mask).sum())\n",
    "    print(atm, (mask & train_mask & ~transit_only_mask).sum(), \n",
    "               (mask & ~train_mask & ~transit_only_mask).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' 16\\nother_seines 0 0\\nother_seines 0 0\\ntuna_purse_seines 14 4\\ntuna_purse_seines 5 4\\nother_purse_seines 1 1\\nother_purse_seines 1 1\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "'''\n",
    "''' 20\n",
    "other_seines 0 0\n",
    "other_seines 0 0\n",
    "tuna_purse_seines 11 4\n",
    "tuna_purse_seines 4 4\n",
    "other_purse_seines 1 0\n",
    "other_purse_seines 1 0\n",
    "'''\n",
    "''' 16\n",
    "other_seines 0 0\n",
    "other_seines 0 0\n",
    "tuna_purse_seines 14 4\n",
    "tuna_purse_seines 5 4\n",
    "other_purse_seines 1 1\n",
    "other_purse_seines 1 1\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "IOError",
     "evalue": "[Errno 2] File classification/data/training_classes_vessel_id.csv does not exist: 'classification/data/training_classes_vessel_id.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-e7ac7c4c3a24>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtraining_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'classification/data/training_classes_vessel_id.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m//anaconda/envs/ml2/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    700\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    703\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/envs/ml2/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 429\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/envs/ml2/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/envs/ml2/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1120\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1121\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1122\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1123\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1124\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/envs/ml2/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1851\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'usecols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1852\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1853\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1854\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1855\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mIOError\u001b[0m: [Errno 2] File classification/data/training_classes_vessel_id.csv does not exist: 'classification/data/training_classes_vessel_id.csv'"
     ]
    }
   ],
   "source": [
    "training_df = pandas.read_csv('classification/data/training_classes_vessel_id.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subset = training_df[['mmsi', 'label', 'length', 'tonnage', 'engine_power', 'crew_size', 'split']]\n",
    "df_subset.to_csv('training_classes_vessel_id_subset.csv', index=False)\n",
    "subprocess.check_call(['gsutil', 'cp', 'training_classes_vessel_id_subset.csv', \n",
    "                      'gs://machine-learning-dev-ttl-120d/training_classes_vessel_id_v20181025.csv'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "getattr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inference_table = 'world-fishing-827.machine_learning_dev_ttl_120d.smoke_test_vessel_inference_v20181024_20170701'\n",
    "label_table = \"world-fishing-827.machine_learning_dev_ttl_120d.training_classes_vessel_id_v20181025\"\n",
    "query = \"\"\"\n",
    "SELECT a.* FROM \n",
    "`{}` a\n",
    "JOIN\n",
    "`{}` b\n",
    "ON a.vessel_id = b.mmsi \n",
    "LIMIT 100\n",
    "\"\"\".format(inference_table, label_table)\n",
    "inference_df = pd.read_gbq(query, project_id='world-fishing-827', dialect='standard')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "label_df = pd.read_gbq(\"select * from `{}`\".format(label_table), project_id='world-fishing-827', dialect='standard')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "python -m classification.metrics.compute_vessel_metrics \\\n",
    "     --inference-table  machine_learning_dev_ttl_120d.smoke_test_vessel_inference_v20181024_ \\\n",
    "     --label-table world-fishing-827.machine_learning_dev_ttl_120d.training_classes_vessel_id_v20181025 \\\n",
    "     --dest-path test_new_vessel_inference.html\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MyModel(model.ModelBase): \n",
    "    def build_inference_net(self):\n",
    "        pass\n",
    "    def build_training_net(self):\n",
    "        pass\n",
    "    @property\n",
    "    def max_window_duration_seconds(self):\n",
    "        # A fixed-length rather than fixed-duration window.\n",
    "        return 0\n",
    "\n",
    "    @property\n",
    "    def window_max_points(self):\n",
    "        return 1024\n",
    "    \n",
    "    def make_input_fn(self, base_feature_path, split, num_parallel_reads):\n",
    "        def training_input_fn():\n",
    "            return (fishing_feature_generation.input_fn(\n",
    "                        self.vessel_metadata,\n",
    "                        self.build_training_file_list(base_feature_path, split),\n",
    "                        self.num_feature_dimensions + 1,\n",
    "                        self.max_window_duration_seconds,\n",
    "                        self.window_max_points,\n",
    "                        self.min_viable_timeslice_length,\n",
    "                        select_ranges=self.use_ranges_for_training,\n",
    "                        num_parallel_reads=num_parallel_reads)\n",
    "                .prefetch(self.batch_size)\n",
    "                .batch(self.batch_size)\n",
    "                )\n",
    "        return training_input_fn\n",
    "    \n",
    "    def make_training_input_fn(self, base_feature_path, num_parallel_reads):\n",
    "        return self.make_input_fn(base_feature_path, utility.TRAINING_SPLIT, num_parallel_reads)\n",
    "    \n",
    "root_feature_path = \"gs://machine-learning-dev-ttl-120d/features/ppb_features_through2017/features\"\n",
    "fishing_range_file = \"classification/data/combined_fishing_ranges_vessel_id.csv\"\n",
    "metadata_file = \"classification/data/training_classes_vessel_id.csv\"\n",
    "\n",
    "fishing_ranges = metadata.read_fishing_ranges(fishing_range_file)\n",
    "all_available_mmsis = metadata.find_available_mmsis(root_feature_path)\n",
    "\n",
    "vessel_metadata = MyModel.read_metadata(\n",
    "        all_available_mmsis, metadata_file,\n",
    "        fishing_ranges, 1)\n",
    "\n",
    "# mdl = MyModel(14, vessel_metadata)\n",
    "# files = mdl.build_training_file_list(root_feature_path , utility.TRAINING_SPLIT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(vessel_metadata.metadata_by_mmsi)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imp\n",
    "import pytz\n",
    "import classification.models.objectives\n",
    "imp.reload(classification.models.objectives)\n",
    "from classification.feature_generation import vessel_feature_generation\n",
    "imp.reload(vessel_feature_generation)\n",
    "from classification.feature_generation import fishing_feature_generation\n",
    "imp.reload(fishing_feature_generation)\n",
    "import classification.models.vessel_characterization\n",
    "imp.reload(classification.models.vessel_characterization)\n",
    "import classification.models.vessel_characterization\n",
    "imp.reload(classification.models.vessel_characterization)\n",
    "from classification.models.vessel_characterization import Model\n",
    "import classification.models.fishing_detection\n",
    "import classification.feature_generation.feature_utilities\n",
    "imp.reload(classification.feature_generation.feature_utilities)\n",
    "from classification.feature_generation.feature_utilities import EPOCH_DT\n",
    "# imp.reload(classification.models.prod.fishing_detection)\n",
    "# from classification.models.prod.fishing_detection import Model\n",
    "\n",
    "mdl = Model(14, vessel_metadata, 'minimal')\n",
    "    \n",
    "time_ranges = [(1328083200, 1343635200), (1343808000, 1359360000), (1359705600, 1375257600), (1375344000, 1390896000), (1391241600, 1406793600), (1406880000, 1422432000), (1422777600, 1438329600), (1438416000, 1453968000), (1454313600, 1469865600), (1470038400, 1485590400), (1485936000, 1501488000), (1501574400, 1517126400)]\n",
    "# time_ranges = [((datetime(2015, 6, 1, tzinfo=pytz.utc) - EPOCH_DT).total_seconds(), (datetime(2015, 7, 1, tzinfo=pytz.utc) - EPOCH_DT).total_seconds())]\n",
    "template = \"gs://machine-learning-dev-ttl-120d/features/ppb_features_through2017/features/{}.tfrecord\"\n",
    "vessel_ids = vessel_metadata.metadata_by_mmsi.keys()[:10]\n",
    "paths = [template.format(x) for x in vessel_ids]\n",
    "\n",
    "# paths = \"\"\"\n",
    "# gs://machine-learning-dev-ttl-120d/features/ppb_features_through2017/features/000007c49-9673-3128-434d-6937d3400dd3.tfrecord\n",
    "# gs://machine-learning-dev-ttl-120d/features/ppb_features_through2017/features/000008a58-83b9-f7c6-e3af-148f962497f4.tfrecord\n",
    "# gs://machine-learning-dev-ttl-120d/features/ppb_features_through2017/features/000020b39-9a62-1a09-60fe-d65a9e39c2cf.tfrecord\n",
    "# gs://machine-learning-dev-ttl-120d/features/ppb_features_through2017/features/000027eb4-4bec-76cc-062b-6ce5cdcac685.tfrecord\n",
    "# gs://machine-learning-dev-ttl-120d/features/ppb_features_through2017/features/000073b65-58c6-abce-7fb1-a842a589aa96.tfrecord\n",
    "# gs://machine-learning-dev-ttl-120d/features/ppb_features_through2017/features/0000747d7-71d7-a018-9e87-d0fbab2adac6.tfrecord\n",
    "# gs://machine-learning-dev-ttl-120d/features/ppb_features_through2017/features/00009b2f0-0822-cdfc-ba1e-a4b05787f7b6.tfrecord\n",
    "# gs://machine-learning-dev-ttl-120d/features/ppb_features_through2017/features/00009f31c-ca68-b94d-11cc-f47ebd7390b8.tfrecord\n",
    "# gs://machine-learning-dev-ttl-120d/features/ppb_features_through2017/features/0000a8ba8-8c4c-255c-59e6-de6c90f79862.tfrecord\n",
    "# gs://machine-learning-dev-ttl-120d/features/ppb_features_through2017/features/0000b163b-b6ee-1b90-63d2-a2a1c6864e5a.tfrecord\n",
    "# \"\"\".strip().split()\n",
    "\n",
    "range_info = (datetime(2017,1,1), datetime(2017, 7, 1))\n",
    "input_fn_p = mdl.make_prediction_input_fn(paths, time_ranges, 32)\n",
    "iter_p = input_fn_p().make_one_shot_iterator()\n",
    "el_p = iter_p.get_next()\n",
    "\n",
    "input_fn_t = mdl.make_training_input_fn(root_feature_path, 32)\n",
    "iter_t = input_fn_t().make_one_shot_iterator()\n",
    "el_t = iter_t.get_next()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "#     while True:\n",
    "        x_p = sess.run(el_p)\n",
    "        x_t = sess.run(el_t)\n",
    "        print(x_p)\n",
    "        print(x_t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_p['features'].shape\n",
    "print(x_p['features'].mean(axis=(0, 1)))\n",
    "print(x_p['features'].std(axis=(0, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_t[0]['features'].mean(axis=(0, 1)))\n",
    "print(x_t[0]['features'].std(axis=(0, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chkpt_path = 'gs://world-fishing-827-dev-ttl30d/data-production/classification/timothyhochberg/vessel_char_v20181023A/models/vessel_characterization'\n",
    "estimator = mdl.make_estimator(chkpt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for result in results:\n",
    "    vid = vessel_metadata.mmsi_map_int2str[int(result['mmsi'])]\n",
    "    cls = metadata.VESSEL_CLASS_DETAILED_NAMES[np.argmax(result['Vessel-class'])]\n",
    "    print(vid[:5], \n",
    "          vessel_metadata.metadata_by_mmsi[vid][0]['label'], cls,\n",
    "          vessel_metadata.metadata_by_mmsi[vid][0]['length'], np.exp(result['Vessel-length']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# So running predictions \"by hand\" works. What about using an Inferer?\n",
    "\n",
    "inferer = run_inference.Inferer(mdl, chkpt_path, root_feature_path)\n",
    "\n",
    "all_results = []\n",
    "for results in inferer.run_inference(vessel_ids, 6, datetime(2015,1,1, tzinfo=pytz.UTC), \n",
    "                                     datetime(2017, 12, 31, tzinfo=pytz.UTC)):\n",
    "    all_results.append(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for result in all_results:\n",
    "    vid = vessel_metadata.mmsi_map_int2str[int(result['mmsi'])]\n",
    "    cls = result['Multiclass']['max_label']\n",
    "    print(vid[:5], \n",
    "          vessel_metadata.metadata_by_mmsi[vid][0]['label'], cls,\n",
    "          vessel_metadata.metadata_by_mmsi[vid][0]['length'], result['length']['value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cmd = r'''\n",
    "docker-compose run vessel_inference  \\\n",
    "                --feature_path {}   \\\n",
    "                --checkpoint_path  {}    \\\n",
    "                --feature_dimensions 14   \\\n",
    "                --results_table=world-fishing-827:machine_learning_dev_ttl_120d.smoke_test_vessel_inference_v20181024_   \\\n",
    "                --start_date 2017-01-01   \\\n",
    "                --end_date 2017-12-31   \\\n",
    "                --project world-fishing-827   \\\n",
    "                --temp_location gs://machine-learning-dev-ttl-30d/scratch/inference   \\\n",
    "                --job_name smoke-test-vessel-inference   \\\n",
    "                --max_num_workers 100   \\\n",
    "                --setup_file ./setup.py   \\\n",
    "                --requirements_file requirements.txt   \\\n",
    "                --runner DataflowRunner  \\\n",
    "                --max_num_workers 100  \\\n",
    "                --worker_machine_type=custom-1-13312-ext\n",
    "'''.format(root_feature_path, chkpt_path)\n",
    "print(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_vessel_ids = vessel_metadata.metadata_by_split['Test'].keys()\n",
    "np.random.seed(888)\n",
    "test_vessel_ids = np.random.choice(test_vessel_ids, 2000)\n",
    "\n",
    "query = \"\"\"\n",
    "SELECT * FROM `world-fishing-827.machine_learning_dev_ttl_120d.smoke_test_vessel_inference_v20181024_*` \n",
    "WHERE _TABLE_SUFFIX >= \"20170101\" AND\n",
    "vessel_id  in ({})\n",
    "LIMIT 1000\n",
    "\"\"\".format(', '.join(['\"{}\"'.format(x) for x in test_vessel_ids]))\n",
    "\n",
    "\n",
    "\n",
    "results_df = pandas.read_gbq(query, project_id='world-fishing-827', dialect='standard')\n",
    "\n",
    "results_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for result in results_df.itertuples():\n",
    "    vid = result.vessel_id\n",
    "    cls = result.max_label\n",
    "    print(vid[:5], \n",
    "          vessel_metadata.metadata_by_mmsi[vid][0]['label'], cls,\n",
    "          vessel_metadata.metadata_by_mmsi[vid][0]['length'], result.length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "keys = [x['label'] for x in results_df.iloc[0].label_scores]\n",
    "x = []\n",
    "y = []\n",
    "for result in results_df.itertuples():\n",
    "    y.append(keys.index(result.max_label))\n",
    "    vid = result.vessel_id\n",
    "    lbl = vessel_metadata.metadata_by_mmsi[vid][0]['label']\n",
    "    x.append(keys.index(lbl))\n",
    "    \n",
    "plt.figure(figsize=(12, 12))\n",
    "plt.plot(x, y, '.', markersize=20, alpha = 0.1)\n",
    "# keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = []\n",
    "y = []\n",
    "for result in results_df.itertuples():\n",
    "    vid = result.vessel_id\n",
    "    length = vessel_metadata.metadata_by_mmsi[vid][0]['length']\n",
    "    if length:\n",
    "        y.append((result.length))\n",
    "        vid = result.vessel_id\n",
    "        length = vessel_metadata.metadata_by_mmsi[vid][0]['length']\n",
    "        x.append(length)\n",
    "    \n",
    "plt.figure(figsize=(12, 12))\n",
    "plt.plot(x, y, '.', markersize=5)\n",
    "len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_fn = mdl.make_test_input_fn(root_feature_path, 32, prefetch=1)\n",
    "dataset = input_fn()\n",
    "iter = dataset.make_one_shot_iterator()\n",
    "el = iter.get_next()\n",
    "with tf.Session() as sess:\n",
    "    el = sess.run(el)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from classification.models.fishing_detection import Model\n",
    "real_mdl = Model(14, vessel_metadata, 'minimal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset = real_mdl.make_test_input_fn(root_feature_path, 4)()\n",
    "iter = dataset.make_one_shot_iterator()\n",
    "el = iter.get_next()\n",
    "with tf.Session() as sess:\n",
    "    el = sess.run(el)\n",
    "el[0][0].shape, el[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train_df = pd.read_csv('classification/data/training_classes_vessel_id.csv')\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mmsis = open('mmsis.txt').read().strip().split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "in_both = set(mmsis) & set(train_df.mmsi)\n",
    "len(in_both)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sorted(mmsis)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sorted(set(train_df.mmsi))[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mapper = pd.read_csv('train/ssvid_to_vessel_id.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sorted(set(mapper.vessel_id))[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fakerator():\n",
    "    while True:\n",
    "        for i in range(3):\n",
    "            yield i\n",
    "        raise StopIteration\n",
    "        \n",
    "f = fakerator()\n",
    "\n",
    "print('a')\n",
    "for x in f:\n",
    "    print x\n",
    "    \n",
    "print('b')\n",
    "for x in f:\n",
    "    print x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "2 + 2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
